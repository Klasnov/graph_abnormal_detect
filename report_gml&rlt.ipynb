{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Generation Models\n",
    "\n",
    "In this section, we utilize the graph-based generation models to detect the abnormal/malicious data in the log dataset. Generation models are able to learn the underlying data distribution of the normal data. When the model is trained on the normal dataset, if a normal data sample is input and forwared through the model, the reconstruction error after the backward propagation should keeps low. However, if the input is an abnormal data sample, the reconstruction error will be relatively much higher. Therefore, through analyzing the reconstruction error, we are able to detect the abnormal data points feeded into the model. We conducted the data analysis leveraging the Denoising Diffusion Probabilistic Model (DDPM), with the Variational Autoencoder (VAE) as the comparison benchmark. Both models are integrated with the Graph Transformer model to capture the graph structure information.\n",
    "\n",
    "The training was conducted on 56,576 normal log graphs with the batch size of 32. Due to the data loeading and training process of generation models are time-consuming, we used sperate Python files to reconstruct the graph data, collate the data batches, train the models, and saved the trained model parameters. The specific code files and example tensor format are available in the GitHub repository [here](https://github.com/Klasnov/graph_abnormal_detect). In this report section, we will show the code snippets ***without*** executed outputs. The code content in this section is adapted from the tutorial code files, with modifications to our specific dataset application, like the explicit positional encoding of the graph structure based on the log sequence.\n",
    "\n",
    "\n",
    "## Training Graph Reconstruction with DGL Library\n",
    "\n",
    "We first load the networkx graph files after the previous data preprocessing. The graph data is then converted to Tensor format with DGL library, as DGL can help to easily extract and manipulate the node and edge features in the graph data.\n",
    "\n",
    "In the networkx graph, the node features we are going to use are the node type in the computational system and the node log ID. Since some ID values are very frequent appearing in the log data, for each graph with specific size of 100 nodes, we reindex the node local ID, as the node positional encoding later, by random values in the range of 0 to 99. This may avoid the model to overfit on the specific global node ID values. The edge features are the operation type between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "NUM_NODE = 100\n",
    "\n",
    "TYPES = [\"THREAD\", \"FILE\", \"REGISTRY\", \"FLOW\", \"USER_SESSION\", \"SERVICE\", \"PROCESS\", \"MODULE\", \"TASK\", \"SHELL\"]\n",
    "TYPE_MAP = {type: i for i, type in enumerate(TYPES)}\n",
    "\n",
    "ACTIONS = [\n",
    "    \"FILE_CREATE\", \"FILE_DELETE\", \"FILE_MODIFY\", \"FILE_READ\", \"FILE_RENAME\",\n",
    "    \"FILE_WRITE\", \"FLOW_MESSAGE\", \"FLOW_OPEN\", \"MODULE_LOAD\", \"PROCESS_CREATE\",\n",
    "    \"PROCESS_OPEN\", \"PROCESS_TERMINATE\", \"REGISTRY_ADD\", \"REGISTRY_EDIT\",\n",
    "    \"REGISTRY_REMOVE\", \"SERVICE_CREATE\", \"SHELL_COMMAND\", \"TASK_CREATE\",\n",
    "    \"TASK_DELETE\", \"TASK_MODIFY\", \"TASK_START\", \"THREAD_CREATE\", \"THREAD_REMOTE_CREATE\",\n",
    "    \"THREAD_TERMINATE\", \"USER_SESSION_GRANT\", \"USER_SESSION_INTERACTIVE\",\"USER_SESSION_LOGIN\",\n",
    "    \"USER_SESSION_LOGOUT\", \"USER_SESSION_REMOTE\", \"USER_SESSION_UNLOCK\"\n",
    "    ]\n",
    "ACTION_MAP = {action: i for i, action in enumerate(ACTIONS)}\n",
    "\n",
    "def nx_to_dgl(nx_graph):\n",
    "    dgl_graph = dgl.graph(([], []))\n",
    "\n",
    "    node_ids = list(nx_graph.nodes)\n",
    "    dgl_graph.add_nodes(len(node_ids))\n",
    "    nx_to_dgl_node_map = {node: i for i, node in enumerate(node_ids)}\n",
    "    if len(node_ids) != NUM_NODE:\n",
    "        raise ValueError(\"Number of nodes in graph is not 100\")\n",
    "    \n",
    "    id_set = set()\n",
    "    for node in node_ids:\n",
    "        node_data = nx_graph.nodes[node]\n",
    "        node_id = node_data.get(\"nodeID\", -1)\n",
    "        id_set.add(node_id)\n",
    "    \n",
    "    # Map nodeIDs to random integer in range of [0, 99], avoid overfitting to nodeIDs\n",
    "    id_set_len = len(id_set)\n",
    "    rand_ids = np.random.choice(100, id_set_len, replace=False)\n",
    "    rand_id_Map = {node_id: rand_id for node_id, rand_id in zip(id_set, rand_ids)}\n",
    "    \n",
    "    # Map node features\n",
    "    node_types = []\n",
    "    ids = []\n",
    "    \n",
    "    for node in node_ids:\n",
    "        node_data = nx_graph.nodes[node]\n",
    "        node_type = node_data.get(\"node_type\", \"\")\n",
    "        node_id = node_data.get(\"nodeID\", -1)\n",
    "        node_types.append(TYPE_MAP.get(node_type, -1))\n",
    "        ids.append(rand_id_Map.get(node_id, -1))\n",
    "    \n",
    "    dgl_graph.ndata[\"type\"] = torch.tensor(node_types, dtype=torch.float32)\n",
    "    dgl_graph.ndata[\"id\"] = torch.tensor(ids, dtype=torch.float32)\n",
    "    \n",
    "    # Map edge features\n",
    "    edges = list(nx_graph.edges(data=True))\n",
    "    src_nodes = []\n",
    "    dst_nodes = []\n",
    "    edge_actions = []\n",
    "    \n",
    "    for edge in edges:\n",
    "        src, dst, edge_data = edge\n",
    "        src_nodes.append(nx_to_dgl_node_map[src])\n",
    "        dst_nodes.append(nx_to_dgl_node_map[dst])\n",
    "        edge_actions.append(ACTION_MAP.get(edge_data.get(\"action\", \"\"), -1))\n",
    "    \n",
    "    dgl_graph.add_edges(src_nodes, dst_nodes)\n",
    "    dgl_graph.edata[\"action\"] = torch.tensor(edge_actions, dtype=torch.float32)\n",
    "    \n",
    "    return dgl_graph\n",
    "\n",
    "\n",
    "\n",
    "dir_path = \"data/train_graphs/\"\n",
    "if not os.path.exists(dir_path):\n",
    "    raise ValueError(\"The path does not exist\")\n",
    "\n",
    "train_graph_list = []\n",
    "for chid_dirs in os.listdir(dir_path):\n",
    "    chid_dirs_path = os.path.join(dir_path, chid_dirs)\n",
    "    if not os.path.isdir(chid_dirs_path):\n",
    "        continue\n",
    "    for file in os.listdir(chid_dirs_path):\n",
    "        if file.endswith(\".gz\"):\n",
    "            file_path = os.path.join(chid_dirs_path, file)\n",
    "            with gzip.open(file_path, \"rb\") as f:\n",
    "                nx_graph = nx.read_gml(f)\n",
    "                dgl_graph = nx_to_dgl(nx_graph)\n",
    "                train_graph_list.append(dgl_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batching and Storage in Tensor Format\n",
    "\n",
    "To make the training process more efficient, we collate the graph data into batches with batch size of 32. The batched graph data is saved in the PyTorch tensor format, which can be directly loaded in the training process.\n",
    "\n",
    "In this process, the edge features are converted from the coordinate sparse matrix format (COO) into the dense weighted adjacency matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def get_weighted_adjacency_matrix(graph):\n",
    "    adj_spr = graph.adjacency_matrix(scipy_fmt=\"coo\")\n",
    "    edge_freq = graph.edata[\"action\"]\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    for i, j, freq in zip(adj_spr.row, adj_spr.col, edge_freq):\n",
    "        adj[i, j] = freq\n",
    "    adj = adj + adj.T\n",
    "    return adj\n",
    "\n",
    "\n",
    "def batch_save(graph_list, path, index, batch_size=32):\n",
    "    if len(graph_list) < batch_size:\n",
    "        batch_size = len(graph_list)\n",
    "    node_type_list = []\n",
    "    node_id_list = []\n",
    "    edge_action_list = []\n",
    "    for graph in graph_list:\n",
    "        node_type_list.append(graph.ndata[\"type\"])\n",
    "        node_id_list.append(graph.ndata[\"id\"])\n",
    "        adj = get_weighted_adjacency_matrix(graph)\n",
    "        edge_action_list.append(adj)\n",
    "    h = torch.cat(node_type_list, dim=0).view(batch_size, 100).long()\n",
    "    pe = torch.cat(node_id_list, dim=0).view(batch_size, 100).long()\n",
    "    e = torch.cat(edge_action_list, dim=0).view(batch_size, 100, 100).long()\n",
    "    torch.save(h, path + \"h_\" + str(index) + \".pt\")\n",
    "    torch.save(pe, path + \"pe_\" + str(index) + \".pt\")\n",
    "    torch.save(e, path + \"e_\" + str(index) + \".pt\")\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "def batch_graph(graph_list=None, batch_size=32, path=\"data/train/\", index=0, load=True):\n",
    "    if not load:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        num_batch = ceil(len(graph_list) / batch_size)\n",
    "        for i in range(num_batch):\n",
    "            end_batch_index = (i + 1) * batch_size\n",
    "            if end_batch_index > len(graph_list):\n",
    "                end_batch_index = len(graph_list)\n",
    "            batch_graph_list = graph_list[i * batch_size: end_batch_index]\n",
    "            save_path = path + \"batch_\" + str(i) + \"/\"\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            batch_save(batch_graph_list, save_path, i)\n",
    "            h = None; pe = None; e = None\n",
    "    else:\n",
    "        save_path = path + \"batch_\" + str(index) + \"/\"\n",
    "        if not os.path.exists(save_path):\n",
    "            raise ValueError(\"The path does not exist\")\n",
    "        h = torch.load(save_path + \"h_\" + str(index) + \".pt\", weights_only=True)\n",
    "        pe = torch.load(save_path + \"pe_\" + str(index) + \".pt\", weights_only=True)\n",
    "        e = torch.load(save_path + \"e_\" + str(index) + \".pt\", weights_only=True)\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "_, _, _ = batch_graph(train_graph_list, batch_size=BATCH_SIZE, load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script for DDPM Model\n",
    "\n",
    "The training script for the Denoising Diffusion Probabilistic Model (DDPM) is shown below. The model is trained with the batched graph data, and the trained model parameters are saved for the later reconstruction and analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_NODE = 100\n",
    "TYPES = [\"THREAD\", \"FILE\", \"REGISTRY\", \"FLOW\", \"USER_SESSION\", \"SERVICE\", \"PROCESS\", \"MODULE\", \"TASK\", \"SHELL\"]\n",
    "ACTIONS = [\n",
    "    \"FILE_CREATE\", \"FILE_DELETE\", \"FILE_MODIFY\", \"FILE_READ\", \"FILE_RENAME\", \"FILE_WRITE\", \"FLOW_MESSAGE\",\n",
    "    \"FLOW_OPEN\", \"MODULE_LOAD\", \"PROCESS_CREATE\", \"PROCESS_OPEN\", \"PROCESS_TERMINATE\", \"REGISTRY_ADD\",\n",
    "    \"REGISTRY_EDIT\", \"REGISTRY_REMOVE\", \"SERVICE_CREATE\", \"SHELL_COMMAND\", \"TASK_CREATE\", \"TASK_DELETE\",\n",
    "    \"TASK_MODIFY\", \"TASK_START\", \"THREAD_CREATE\", \"THREAD_REMOTE_CREATE\", \"THREAD_TERMINATE\", \"USER_SESSION_GRANT\",\n",
    "    \"USER_SESSION_INTERACTIVE\",\"USER_SESSION_LOGIN\", \"USER_SESSION_LOGOUT\", \"USER_SESSION_REMOTE\", \"USER_SESSION_UNLOCK\"\n",
    "]\n",
    "NUM_BATCH = 1768\n",
    "NUM_GRAPH = NUM_BATCH * BATCH_SIZE\n",
    "NUM_WARMUP = 2 * max(NUM_NODE, NUM_GRAPH // BATCH_SIZE)\n",
    "\n",
    "EPOCH_NUM = 1000\n",
    "INIT_LR = 0.0003\n",
    "\n",
    "\n",
    "def get_weighted_adjacency_matrix(graph):\n",
    "    adj_spr = graph.adjacency_matrix(scipy_fmt=\"coo\")\n",
    "    edge_freq = graph.edata[\"action\"]\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    for i, j, freq in zip(adj_spr.row, adj_spr.col, edge_freq):\n",
    "        adj[i, j] = freq\n",
    "    adj = adj + adj.T\n",
    "    return adj\n",
    "\n",
    "\n",
    "def get_batch(path=\"data/train/\", index=0):\n",
    "    save_path = path + \"batch_\" + str(index) + \"/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        raise ValueError(\"The path does not exist\")\n",
    "    h = torch.load(save_path + \"h_\" + str(index) + \".pt\", weights_only=True)\n",
    "    pe = torch.load(save_path + \"pe_\" + str(index) + \".pt\", weights_only=True)\n",
    "    e = torch.load(save_path + \"e_\" + str(index) + \".pt\", weights_only=True)\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "def sym_tensor(x):\n",
    "    x = x.permute(0, 3, 1, 2) # [bs, n, n, d]\n",
    "    triu = torch.triu(x,diagonal=1).transpose(3,2) # [bs, d, n, n]\n",
    "    mask = (triu.abs()>0).float()                  # [bs, d, n, n]\n",
    "    x =  x * (1 - mask ) + mask * triu             # [bs, d, n, n]\n",
    "    x = x.permute(0, 2, 3, 1) # [bs, n, n, d]\n",
    "    return x               # [bs, n, n, d]\n",
    "\n",
    "class Embed_G(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        d = params[\"d\"]\n",
    "        self.Embed_h = nn.Embedding(params[\"num_type\"], d)\n",
    "        self.Embed_e = nn.Embedding(params[\"num_action\"], d)\n",
    "        self.Embed_pe = nn.Embedding(params[\"num_node\"], d)\n",
    "    \n",
    "    def forward(self, h, e, pe):\n",
    "        pe = self.Embed_pe(pe) # [bs, n, d]\n",
    "        h = self.Embed_h(h)\n",
    "        h = h + pe\n",
    "        e = self.Embed_e(e) # [bs, n, n, d]\n",
    "        e = e + pe.unsqueeze(1) + pe.unsqueeze(2)\n",
    "        e = sym_tensor(e)\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class Attention_Layer(nn.Module):\n",
    "    def __init__(self, d, d_head, drop):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(d, d_head)\n",
    "        self.K = nn.Linear(d, d_head)\n",
    "        self.V = nn.Linear(d, d_head)\n",
    "        self.E = nn.Linear(d, d_head)\n",
    "        self.Ni = nn.Linear(d, d_head)\n",
    "        self.Nj = nn.Linear(d, d_head)\n",
    "        self.Drop_Att = nn.Dropout(drop)\n",
    "        self.sqrt_d = torch.sqrt(torch.tensor(d_head))\n",
    "    \n",
    "    def forward(self, h, e):\n",
    "        # h: [bs, n, d]; e: [bs, n, n, d]\n",
    "        Q = self.Q(h) # [bs, n, d_head]\n",
    "        K = self.K(h)\n",
    "        V = self.V(h)\n",
    "        Q = Q.unsqueeze(2)  # [bs, n, 1, d_head]\n",
    "        K = K.unsqueeze(1)  # [bs, 1, n, d_head]\n",
    "        E = self.E(e)       # [bs, n, n, d_head]\n",
    "        Ni = self.Ni(h).unsqueeze(2) # [bs, n, 1, d_head]\n",
    "        Nj = self.Nj(h).unsqueeze(1) # [bs, 1, n, d_head]\n",
    "        e = E + Ni + Nj              # [bs, n, n, d_head]\n",
    "        Att = (Q * e * K).sum(dim=-1) / self.sqrt_d # [bs, n, n]\n",
    "        Att = torch.softmax(Att, dim=1)             # [bs, n, n]\n",
    "        Att = self.Drop_Att(Att)\n",
    "        h = Att @ V # [bs, n, d_head]\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class MAH_Layer(nn.Module):\n",
    "    def __init__(self, d, head_num, drop):\n",
    "        super().__init__()\n",
    "        d_head = d // head_num\n",
    "        self.heads = nn.ModuleList([Attention_Layer(d, d_head, drop) for _ in range(head_num)])\n",
    "        self.WO_h = nn.Linear(d, d)\n",
    "        self.WO_e = nn.Linear(d, d)\n",
    "        self.Drop_h = nn.Dropout(drop)\n",
    "        self.Drop_e = nn.Dropout(drop)\n",
    "    \n",
    "    def forward(self, h, e):\n",
    "        # h: [bs, n, d]; e: [bs, n, n, d]\n",
    "        h_MHA = []\n",
    "        e_MHA = []\n",
    "        for head in self.heads:\n",
    "            h_mha, e_mha = head(h, e)\n",
    "            h_MHA.append(h_mha)\n",
    "            e_MHA.append(e_mha)\n",
    "        h = self.Drop_h(self.WO_h(torch.cat(h_MHA, dim=2)))\n",
    "        e = self.Drop_e(self.WO_e(torch.cat(e_MHA, dim=3)))\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class GT_Layer(nn.Module):\n",
    "    def __init__(self, d, num_head, drop):\n",
    "        super().__init__()\n",
    "        self.Norm_h_1 = nn.LayerNorm(d)\n",
    "        self.Norm_e_1 = nn.LayerNorm(d)\n",
    "        self.MHA = MAH_Layer(d, num_head, drop)\n",
    "        self.Norm_h_2 = nn.LayerNorm(d)\n",
    "        self.Norm_e_2 = nn.LayerNorm(d)\n",
    "        self.MLP_h = nn.Sequential(nn.Linear(d, 4*d), nn.ReLU(), nn.Linear(4*d, d))\n",
    "        self.MLP_e = nn.Sequential(nn.Linear(d, 4*d), nn.ReLU(), nn.Linear(4*d, d))\n",
    "        self.Drop_h = nn.Dropout(drop)\n",
    "        self.Drop_e = nn.Dropout(drop)\n",
    "    \n",
    "    def forward(self, h, e):\n",
    "        # h: [bs, n, d]; e: [bs, n, n, d]\n",
    "        h = self.Norm_h_1(h)\n",
    "        e = self.Norm_e_1(e)\n",
    "        h_MHA, e_MHA = self.MHA(h, e)\n",
    "        h = h + h_MHA\n",
    "        h = h + self.MLP_h(self.Norm_h_2(h))\n",
    "        e = e + e_MHA\n",
    "        e = e + self.MLP_e(self.Norm_e_2(e))\n",
    "        h = self.Drop_h(h)\n",
    "        e = self.Drop_e(e)\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        d = params[\"d\"]\n",
    "        # Graph Embedding\n",
    "        self.num_node = params[\"num_node\"]\n",
    "        self.num_t = params[\"num_t\"]\n",
    "        self.num_type = params[\"num_type\"]\n",
    "        self.num_action = params[\"num_action\"]\n",
    "        self.Embed_h = nn.Linear(self.num_type, d)\n",
    "        self.Embed_e = nn.Linear(self.num_action, d)\n",
    "        self.pe_h = nn.Embedding(self.num_node, d)\n",
    "        # Time Embedding\n",
    "        self.pe_t = nn.Sequential(nn.Embedding(self.num_t, d), nn.ReLU(), nn.Linear(d, d))\n",
    "        # GT Layers\n",
    "        num_gt_layer = params[\"num_gt_layer\"]\n",
    "        num_head = params[\"num_head\"]\n",
    "        drop = params[\"drop\"]\n",
    "        self.GT_Layers = nn.ModuleList([GT_Layer(d, num_head, drop) for _ in range(num_gt_layer)])\n",
    "        # Output Layer\n",
    "        self.LN_h = nn.Linear(d, self.num_type)\n",
    "        self.LN_e = nn.Linear(d, self.num_action)\n",
    "    \n",
    "    def forward(self, h, e, pe_h, sample_t):\n",
    "        # Embedding for Graph\n",
    "        pe_h = self.pe_h(pe_h) # [bs, n, d]\n",
    "        h_t = self.Embed_h(h)\n",
    "        h_t = h_t + pe_h\n",
    "        e_t = self.Embed_e(e) # [bs, n, n, d]\n",
    "        e_t = e_t + pe_h.unsqueeze(1)\n",
    "        e_t = sym_tensor(e_t)\n",
    "        # Embedding for Time\n",
    "        pe_t = self.pe_t(sample_t) # [bs, d]\n",
    "        # GT Layers\n",
    "        for GT_Layer in self.GT_Layers:\n",
    "            h_t = h_t + pe_t.unsqueeze(1) # [bs, n, d]\n",
    "            e_t = e_t + pe_t.unsqueeze(1).unsqueeze(2) # [bs, n, n, d]\n",
    "            h_t, e_t = GT_Layer(h_t, e_t)\n",
    "            e_t = sym_tensor(e_t)\n",
    "        # Output Layer\n",
    "        h_t_minus_one = self.LN_h(h_t)\n",
    "        e_t_minus_one = self.LN_e(e_t)\n",
    "        return h_t_minus_one, e_t_minus_one\n",
    "    \n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, num_t, beta_1, beta_t, params):\n",
    "        super().__init__()\n",
    "        self.device = params[\"device\"]\n",
    "        self.num_type = params[\"num_type\"]\n",
    "        self.num_action = params[\"num_action\"]\n",
    "        self.UNet = UNet(params)\n",
    "        self.num_t = num_t\n",
    "        self.alpha_t = 1.0 - torch.linspace(beta_1, beta_t, num_t).to(self.device)\n",
    "        self.alpha_bar_t = torch.cumprod(self.alpha_t, dim=0)\n",
    "    \n",
    "    def forward(self, h_0, e_0, sample_t, noise_h0, noise_e0):\n",
    "        h0 = torch.nn.functional.one_hot(h_0, self.num_type).float()\n",
    "        e0 = torch.nn.functional.one_hot(e_0, self.num_action).float()\n",
    "        bs = len(sample_t)\n",
    "        sqrt_alpha_bar_t = torch.sqrt(self.alpha_bar_t[sample_t])\n",
    "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1.0 - self.alpha_bar_t[sample_t])\n",
    "        h_t = sqrt_alpha_bar_t.view(bs, 1, 1) * h0 + sqrt_one_minus_alpha_bar_t.view(bs, 1, 1) * noise_h0\n",
    "        e_t = sqrt_alpha_bar_t.view(bs, 1, 1, 1) * e0 + sqrt_one_minus_alpha_bar_t.view(bs, 1, 1, 1) * noise_e0\n",
    "        return h_t, e_t\n",
    "    \n",
    "    def backward(self, h_t, e_t, pe_h, sample_t):\n",
    "        noise_pred_h_t, noise_pred_e_t = self.UNet(h_t, e_t, pe_h, sample_t)\n",
    "        return noise_pred_h_t, noise_pred_e_t\n",
    "    \n",
    "\n",
    "def train_ddpm(num_t, beta_1, beta_t, net_params, load_save=True, model_path=\"model/ddpm/\"):\n",
    "    torch.random.manual_seed(0)\n",
    "    ddpm = DDPM(num_t, beta_1, beta_t, net_params).to(DEVICE)\n",
    "    if load_save:\n",
    "        if os.path.exists(model_path + \"ddpm.pt\"):\n",
    "            ddpm.load_state_dict(torch.load(model_path + \"ddpm.pt\", weights_only=True))\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    init_lr = INIT_LR\n",
    "    optimizer = torch.optim.AdamW(ddpm.parameters(), lr=init_lr)\n",
    "    scheduler_warmup = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: min((t+1)/NUM_WARMUP, 1.0))\n",
    "    scheduler_tracker = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1)\n",
    "\n",
    "    num_epoch = EPOCH_NUM\n",
    "    num_warmup_batch = 0\n",
    "\n",
    "    train_loss_drop_patience = 5\n",
    "    loss_dropping = True\n",
    "    train_loss_drop_cnt = 0\n",
    "    previous_best_loss = float(\"inf\")\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        num_batch = 0\n",
    "\n",
    "        ddpm.train()\n",
    "\n",
    "        for i in range(NUM_BATCH):\n",
    "            h, pe, e = get_batch(index=i)\n",
    "            h = h.to(DEVICE)\n",
    "            pe = pe.to(DEVICE)\n",
    "            e = e.to(DEVICE)\n",
    "            batch_sample_t = torch.randint(0, num_t, (BATCH_SIZE,)).long().to(DEVICE)\n",
    "            batch_noise_h_t = torch.randn(BATCH_SIZE, NUM_NODE, len(TYPES)).to(DEVICE)\n",
    "            batch_noise_e_t = torch.randn(BATCH_SIZE, NUM_NODE, NUM_NODE, len(ACTIONS)).to(DEVICE)\n",
    "            batch_noise_e_t = sym_tensor(batch_noise_e_t)\n",
    "\n",
    "            h_t, e_t = ddpm(h, e, batch_sample_t, batch_noise_h_t, batch_noise_e_t)\n",
    "            noise_pred_h_t, noise_pred_e_t = ddpm.backward(h_t, e_t, pe, batch_sample_t)\n",
    "\n",
    "            loss = torch.nn.MSELoss()(noise_pred_h_t, batch_noise_h_t) + torch.nn.MSELoss()(noise_pred_e_t, batch_noise_e_t)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if num_batch < NUM_WARMUP:\n",
    "                scheduler_warmup.step()\n",
    "            num_batch += 1\n",
    "\n",
    "            running_loss += loss.detach().item()\n",
    "            num_batch += 1\n",
    "\n",
    "            del h, pe, e, batch_sample_t, batch_noise_h_t, batch_noise_e_t, h_t, e_t, noise_pred_h_t, noise_pred_e_t\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        mean_loss = running_loss / num_batch\n",
    "        if num_warmup_batch >= NUM_WARMUP:\n",
    "            scheduler_tracker.step(mean_loss)\n",
    "        elapsed = (time.time() - start) / 60\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch}  Loss: {mean_loss:.6f}  lr: {optimizer.param_groups[0]['lr']:.6f}  Time: {elapsed:.2f} mins\")\n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] < 1e-5:\n",
    "            print(\"Early stopping since lr < 1e-5\")\n",
    "            break\n",
    "\n",
    "        if mean_loss < previous_best_loss:\n",
    "            previous_best_loss = mean_loss\n",
    "            train_loss_drop_cnt = 0\n",
    "            loss_dropping = True\n",
    "        else:\n",
    "            train_loss_drop_cnt += 1\n",
    "            loss_dropping = False\n",
    "            if train_loss_drop_cnt >= train_loss_drop_patience:\n",
    "                print(\"Early stopping since loss is not dropping\")\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 and loss_dropping:\n",
    "            torch.save(ddpm.state_dict(), model_path + \"ddpm.pt\")\n",
    "    \n",
    "    torch.save(ddpm.state_dict(), model_path + \"ddpm.pt\")\n",
    "    print(f\"Finished the training of DDPM, with the best loss {previous_best_loss:.6f}, and the total time {elapsed:.2f} mins\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    beta_1 = 0.0001\n",
    "    beta_t = 0.1\n",
    "    num_t = 200\n",
    "\n",
    "    ddpm_net_params = {\n",
    "        \"num_type\": len(TYPES),\n",
    "        \"num_action\": len(ACTIONS),\n",
    "        \"num_node\": NUM_NODE,\n",
    "        \"num_gt_layer\": 6,\n",
    "        \"num_head\": 4,\n",
    "        \"d\": 32 * 4,\n",
    "        \"num_t\": num_t,\n",
    "        \"drop\": 0,\n",
    "        \"device\": DEVICE\n",
    "    }\n",
    "\n",
    "    train_ddpm(num_t, beta_1, beta_t, ddpm_net_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script for VAE Model\n",
    "\n",
    "The training script for the Variational Autoencoder (VAE) model is shown below. The model is trained with the batched graph data, and the trained model parameters are saved for the later reconstruction and analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_NODE = 100\n",
    "TYPES = [\"THREAD\", \"FILE\", \"REGISTRY\", \"FLOW\", \"USER_SESSION\", \"SERVICE\", \"PROCESS\", \"MODULE\", \"TASK\", \"SHELL\"]\n",
    "ACTIONS = [\n",
    "    \"FILE_CREATE\", \"FILE_DELETE\", \"FILE_MODIFY\", \"FILE_READ\", \"FILE_RENAME\", \"FILE_WRITE\", \"FLOW_MESSAGE\",\n",
    "    \"FLOW_OPEN\", \"MODULE_LOAD\", \"PROCESS_CREATE\", \"PROCESS_OPEN\", \"PROCESS_TERMINATE\", \"REGISTRY_ADD\",\n",
    "    \"REGISTRY_EDIT\", \"REGISTRY_REMOVE\", \"SERVICE_CREATE\", \"SHELL_COMMAND\", \"TASK_CREATE\", \"TASK_DELETE\",\n",
    "    \"TASK_MODIFY\", \"TASK_START\", \"THREAD_CREATE\", \"THREAD_REMOTE_CREATE\", \"THREAD_TERMINATE\", \"USER_SESSION_GRANT\",\n",
    "    \"USER_SESSION_INTERACTIVE\",\"USER_SESSION_LOGIN\", \"USER_SESSION_LOGOUT\", \"USER_SESSION_REMOTE\", \"USER_SESSION_UNLOCK\"\n",
    "]\n",
    "NUM_BATCH = 1768\n",
    "NUM_GRAPH = NUM_BATCH * BATCH_SIZE\n",
    "NUM_WARMUP = 2 * max(NUM_NODE, NUM_GRAPH // BATCH_SIZE)\n",
    "\n",
    "EPOCH_NUM = 1000\n",
    "INIT_LR = 0.0003\n",
    "\n",
    "\n",
    "def get_weighted_adjacency_matrix(graph):\n",
    "    adj_spr = graph.adjacency_matrix(scipy_fmt=\"coo\")\n",
    "    edge_freq = graph.edata[\"action\"]\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    for i, j, freq in zip(adj_spr.row, adj_spr.col, edge_freq):\n",
    "        adj[i, j] = freq\n",
    "    adj = adj + adj.T\n",
    "    return adj\n",
    "\n",
    "\n",
    "def get_batch(path=\"data/train/\", index=0):\n",
    "    save_path = path + \"batch_\" + str(index) + \"/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        raise ValueError(\"The path does not exist\")\n",
    "    h = torch.load(save_path + \"h_\" + str(index) + \".pt\", weights_only=True)\n",
    "    pe = torch.load(save_path + \"pe_\" + str(index) + \".pt\", weights_only=True)\n",
    "    e = torch.load(save_path + \"e_\" + str(index) + \".pt\", weights_only=True)\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "def sym_tensor(x):\n",
    "    x = x.permute(0, 3, 1, 2) # [bs, n, n, d]\n",
    "    triu = torch.triu(x,diagonal=1).transpose(3,2) # [bs, d, n, n]\n",
    "    mask = (triu.abs()>0).float()                  # [bs, d, n, n]\n",
    "    x =  x * (1 - mask ) + mask * triu             # [bs, d, n, n]\n",
    "    x = x.permute(0, 2, 3, 1) # [bs, n, n, d]\n",
    "    return x               # [bs, n, n, d]\n",
    "\n",
    "class Embed_G(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        d = params[\"d\"]\n",
    "        self.Embed_h = nn.Embedding(params[\"num_type\"], d)\n",
    "        self.Embed_e = nn.Embedding(params[\"num_action\"], d)\n",
    "        self.Embed_pe = nn.Embedding(params[\"num_node\"], d)\n",
    "    \n",
    "    def forward(self, h, e, pe):\n",
    "        pe = self.Embed_pe(pe) # [bs, n, d]\n",
    "        h = self.Embed_h(h)\n",
    "        h = h + pe\n",
    "        e = self.Embed_e(e) # [bs, n, n, d]\n",
    "        e = e + pe.unsqueeze(1)\n",
    "        e = sym_tensor(e)\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class Attention_Layer(nn.Module):\n",
    "    def __init__(self, d, d_head, drop):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(d, d_head)\n",
    "        self.K = nn.Linear(d, d_head)\n",
    "        self.V = nn.Linear(d, d_head)\n",
    "        self.E = nn.Linear(d, d_head)\n",
    "        self.Ni = nn.Linear(d, d_head)\n",
    "        self.Nj = nn.Linear(d, d_head)\n",
    "        self.Drop_Att = nn.Dropout(drop)\n",
    "        self.sqrt_d = torch.sqrt(torch.tensor(d_head))\n",
    "    \n",
    "    def forward(self, h, e):\n",
    "        # h: [bs, n, d]; e: [bs, n, n, d]\n",
    "        Q = self.Q(h) # [bs, n, d_head]\n",
    "        K = self.K(h)\n",
    "        V = self.V(h)\n",
    "        Q = Q.unsqueeze(2)  # [bs, n, 1, d_head]\n",
    "        K = K.unsqueeze(1)  # [bs, 1, n, d_head]\n",
    "        E = self.E(e)       # [bs, n, n, d_head]\n",
    "        Ni = self.Ni(h).unsqueeze(2) # [bs, n, 1, d_head]\n",
    "        Nj = self.Nj(h).unsqueeze(1) # [bs, 1, n, d_head]\n",
    "        e = E + Ni + Nj              # [bs, n, n, d_head]\n",
    "        Att = (Q * e * K).sum(dim=-1) / self.sqrt_d # [bs, n, n]\n",
    "        Att = torch.softmax(Att, dim=1)             # [bs, n, n]\n",
    "        Att = self.Drop_Att(Att)\n",
    "        h = Att @ V # [bs, n, d_head]\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class MAH_Layer(nn.Module):\n",
    "    def __init__(self, d, head_num, drop):\n",
    "        super().__init__()\n",
    "        d_head = d // head_num\n",
    "        self.heads = nn.ModuleList([Attention_Layer(d, d_head, drop) for _ in range(head_num)])\n",
    "        self.WO_h = nn.Linear(d, d)\n",
    "        self.WO_e = nn.Linear(d, d)\n",
    "        self.Drop_h = nn.Dropout(drop)\n",
    "        self.Drop_e = nn.Dropout(drop)\n",
    "    \n",
    "    def forward(self, h, e):\n",
    "        # h: [bs, n, d]; e: [bs, n, n, d]\n",
    "        h_MHA = []\n",
    "        e_MHA = []\n",
    "        for head in self.heads:\n",
    "            h_mha, e_mha = head(h, e)\n",
    "            h_MHA.append(h_mha)\n",
    "            e_MHA.append(e_mha)\n",
    "        h = self.Drop_h(self.WO_h(torch.cat(h_MHA, dim=2)))\n",
    "        e = self.Drop_e(self.WO_e(torch.cat(e_MHA, dim=3)))\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class GT_Layer(nn.Module):\n",
    "    def __init__(self, d, num_head, drop):\n",
    "        super().__init__()\n",
    "        self.Norm_h_1 = nn.LayerNorm(d)\n",
    "        self.Norm_e_1 = nn.LayerNorm(d)\n",
    "        self.MHA = MAH_Layer(d, num_head, drop)\n",
    "        self.Norm_h_2 = nn.LayerNorm(d)\n",
    "        self.Norm_e_2 = nn.LayerNorm(d)\n",
    "        self.MLP_h = nn.Sequential(nn.Linear(d, 4*d), nn.ReLU(), nn.Linear(4*d, d))\n",
    "        self.MLP_e = nn.Sequential(nn.Linear(d, 4*d), nn.ReLU(), nn.Linear(4*d, d))\n",
    "        self.Drop_h = nn.Dropout(drop)\n",
    "        self.Drop_e = nn.Dropout(drop)\n",
    "    \n",
    "    def forward(self, h, e):\n",
    "        # h: [bs, n, d]; e: [bs, n, n, d]\n",
    "        h = self.Norm_h_1(h)\n",
    "        e = self.Norm_e_1(e)\n",
    "        h_MHA, e_MHA = self.MHA(h, e)\n",
    "        h = h + h_MHA\n",
    "        h = h + self.MLP_h(self.Norm_h_2(h))\n",
    "        e = e + e_MHA\n",
    "        e = e + self.MLP_e(self.Norm_e_2(e))\n",
    "        h = self.Drop_h(h)\n",
    "        e = self.Drop_e(e)\n",
    "        return h, e\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        d = params[\"d\"]\n",
    "        \n",
    "        # Graph Embedding\n",
    "        self.num_node = params[\"num_node\"]\n",
    "        self.Embed_he = Embed_G(params)\n",
    "        self.Embed_pe = nn.Embedding(params[\"num_node\"], d)\n",
    "\n",
    "        # GT Layers\n",
    "        num_enc_layer = params[\"num_enc_layer\"]\n",
    "        num_dec_layer = params[\"num_dec_layer\"]\n",
    "        num_head = params[\"num_head\"]\n",
    "        drop = params[\"drop\"]\n",
    "        self.Enc_Layers = nn.ModuleList([GT_Layer(d, num_head, drop) for _ in range(num_enc_layer)])\n",
    "        self.Dec_Layers = nn.ModuleList([GT_Layer(d, num_head, drop) for _ in range(num_dec_layer)])\n",
    "\n",
    "        # Encoder\n",
    "        dz = params[\"dz\"]\n",
    "        self.LN_q_mu = nn.Linear(d, dz)\n",
    "        self.LN_q_logvar = nn.Linear(d, dz)\n",
    "\n",
    "        # Decoder\n",
    "        self.LN_p = nn.Linear(dz, d)\n",
    "\n",
    "        # Output Layer\n",
    "        self.Norm_Out_h = nn.LayerNorm(d)\n",
    "        self.Norm_Out_e = nn.LayerNorm(d)\n",
    "        self.LN_h = nn.Linear(d, params[\"num_type\"])\n",
    "        self.LN_e = nn.Linear(d, params[\"num_action\"])\n",
    "    \n",
    "    def forward(self, h, e, pe, num_node=None):\n",
    "        if num_node is None:\n",
    "            num_node = self.num_node\n",
    "\n",
    "        # Embedding\n",
    "        h, e = self.Embed_he(h, e, pe)\n",
    "        n = h.size(1)\n",
    "        pe = self.Embed_pe(pe)\n",
    "        # Encoder\n",
    "        for Enc_Layer in self.Enc_Layers:\n",
    "            h, e = Enc_Layer(h, e)\n",
    "            e = sym_tensor(e)\n",
    "        graph_token = h.mean(dim=1)\n",
    "        q_mu = self.LN_q_mu(graph_token)\n",
    "        q_logvar = self.LN_q_logvar(graph_token)\n",
    "        q_std = torch.exp(q_logvar / 2)\n",
    "        eps = torch.randn_like(q_std)\n",
    "        z = q_mu + eps * q_std # [bs, dz]\n",
    "        n = h.size(1)\n",
    "\n",
    "        # Decoder\n",
    "        z = self.LN_p(z) # [bs, d]\n",
    "        h = z.unsqueeze(1).repeat(1, n, 1) # [bs, n, d]\n",
    "        h = h + pe\n",
    "        e = z.unsqueeze(1).unsqueeze(1).repeat(1, n, n, 1) # [bs, n, n, d]\n",
    "        e = e + pe.unsqueeze(1) + pe.unsqueeze(2)\n",
    "        e = sym_tensor(e)\n",
    "        for Dec_Layer in self.Dec_Layers:\n",
    "            h, e = Dec_Layer(h, e)\n",
    "            e = sym_tensor(e)\n",
    "        h = self.Norm_Out_h(h)\n",
    "        e = self.Norm_Out_e(e)\n",
    "        h = self.LN_h(h)\n",
    "        e = self.LN_e(e)\n",
    "        return h, e, q_mu, q_logvar\n",
    "    \n",
    "\n",
    "def train_vae(net_params, load_save=True, model_path=\"model/vae/\"):\n",
    "    torch.random.manual_seed(0)\n",
    "    vae = VAE(net_params).to(DEVICE)\n",
    "    if load_save:\n",
    "        if os.path.exists(model_path + \"vae.pt\"):\n",
    "            vae.load_state_dict(torch.load(model_path + \"vae.pt\", weights_only=True))\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    init_lr = INIT_LR\n",
    "    optimizer = torch.optim.AdamW(vae.parameters(), lr=init_lr)\n",
    "    scheduler_warmup = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: min((t+1)/NUM_WARMUP, 1.0))\n",
    "    scheduler_tracker = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1)\n",
    "\n",
    "    num_epoch = EPOCH_NUM\n",
    "    num_warmup_batch = 0\n",
    "\n",
    "    train_loss_drop_patience = 5\n",
    "    loss_dropping = True\n",
    "    train_loss_drop_cnt = 0\n",
    "    previous_best_loss = float(\"inf\")\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        num_batch = 0\n",
    "\n",
    "        vae.train()\n",
    "\n",
    "        for i in range(NUM_BATCH):\n",
    "            h, pe, e = get_batch(index=i)\n",
    "            h = h.to(DEVICE)\n",
    "            pe = pe.to(DEVICE)\n",
    "            e = e.to(DEVICE)\n",
    "            \n",
    "            pred_h, pred_e, q_mu, q_logvar = vae(h, e, pe)\n",
    "            loss_data = torch.nn.CrossEntropyLoss()(pred_h.view(BATCH_SIZE * NUM_NODE, len(TYPES)), h.view(BATCH_SIZE * NUM_NODE)) \n",
    "            loss_data += torch.nn.CrossEntropyLoss()(pred_e.view(BATCH_SIZE * NUM_NODE * NUM_NODE, len(ACTIONS)), e.view(BATCH_SIZE * NUM_NODE * NUM_NODE))\n",
    "            loss_kl = -0.5 * torch.sum(1 + q_logvar - q_mu.pow(2) - q_logvar.exp())\n",
    "            loss = 2.5 * loss_data + loss_kl\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), 0.25)\n",
    "            optimizer.step()\n",
    "\n",
    "            if num_batch < NUM_WARMUP:\n",
    "                scheduler_warmup.step()\n",
    "            num_batch += 1\n",
    "\n",
    "            running_loss += loss.detach().item()\n",
    "            num_batch += 1\n",
    "\n",
    "            del h, pe, e, pred_h, pred_e, q_mu, q_logvar, loss_data, loss_kl, loss\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        mean_loss = running_loss / num_batch\n",
    "        if num_warmup_batch >= NUM_WARMUP:\n",
    "            scheduler_tracker.step(mean_loss)\n",
    "        elapsed = (time.time() - start) / 60\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch}  Loss: {mean_loss:.6f}  lr: {optimizer.param_groups[0]['lr']:.6f}  Time: {elapsed:.2f} mins\")\n",
    "\n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] < 1e-6:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        if mean_loss < previous_best_loss:\n",
    "            previous_best_loss = mean_loss\n",
    "            train_loss_drop_cnt = 0\n",
    "            loss_dropping = True\n",
    "        else:\n",
    "            train_loss_drop_cnt += 1\n",
    "            loss_dropping = False\n",
    "            if train_loss_drop_cnt >= train_loss_drop_patience:\n",
    "                print(\"Early stopping since loss is not dropping\")\n",
    "                break\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 and loss_dropping:\n",
    "            torch.save(vae.state_dict(), model_path + \"vae.pt\")\n",
    "    \n",
    "    torch.save(vae.state_dict(), model_path + \"vae.pt\")\n",
    "    print(f\"Finished the training of VAE, with the best loss {previous_best_loss:.6f}, and the total time {elapsed:.2f} mins\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vae_net_params = {\n",
    "        \"num_type\": len(TYPES),\n",
    "        \"num_action\": len(ACTIONS),\n",
    "        \"num_node\": NUM_NODE,\n",
    "        \"num_enc_layer\": 4,\n",
    "        \"num_dec_layer\": 4,\n",
    "        \"num_head\": 8,\n",
    "        \"drop\": 0,\n",
    "        \"d\": 16 * 8,\n",
    "        \"dz\": 32\n",
    "    }\n",
    "\n",
    "    train_vae(vae_net_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The seperated training code Python files, example batches of graph data in tensor format, and the trained model parameters are available in the GitHub repository [here](https://github.com/Klasnov/graph_abnormal_detect)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Results\n",
    "\n",
    "In this section, we will evaluate the trained DDPM and VAE models on the normal and abnormal log data. The reconstruction error of the models will be calculated and analyzed to detect the abnormal data points in the log dataset.\n",
    "\n",
    "The analysis here is based on the assumption that data points following the Gaussian distribution. Based on the random subset of the normal training data, we leveraged its mean $\\mu$ and standard deviation $\\sigma$ to calculate the possibility $f(x)=\\frac{1}{\\sqrt{2\\pi{\\sigma}^2}}e^{-\\frac{(x-\\mu)^2}{2{\\sigma}^2}}$ of the unseen data point $x$ being normal or abnormal.\n",
    "\n",
    "\n",
    "## Random Subset of Normal Training Data\n",
    "\n",
    "A random subset of the normal training data is selected to calculate the mean and standard deviation of the reconstruction error. The subset contains 10% of the normal training data, which is consisted of 177 training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "MAX_BATCH = 1768\n",
    "NUM_BATCH = 177\n",
    "\n",
    "\n",
    "def get_batch(path=\"data/train/\", index=0):\n",
    "    save_path = path + \"batch_\" + str(index) + \"/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        raise ValueError(f\"The path does not exist: {save_path}\")\n",
    "    h = torch.load(save_path + \"h_\" + str(index) + \".pt\", weights_only=True)\n",
    "    pe = torch.load(save_path + \"pe_\" + str(index) + \".pt\", weights_only=True)\n",
    "    e = torch.load(save_path + \"e_\" + str(index) + \".pt\", weights_only=True)\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "rand_indices = torch.randperm(MAX_BATCH)\n",
    "pick_indices = rand_indices[:NUM_BATCH]\n",
    "pick_indices = pick_indices.tolist()\n",
    "for i in range(NUM_BATCH):\n",
    "    h, pe, e = get_batch(index=pick_indices[i])\n",
    "    if i == 0:\n",
    "        h_all = h\n",
    "        pe_all = pe\n",
    "        e_all = e\n",
    "    else:\n",
    "        h_all = torch.cat((h_all, h), dim=0)\n",
    "        pe_all = torch.cat((pe_all, pe), dim=0)\n",
    "        e_all = torch.cat((e_all, e), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
