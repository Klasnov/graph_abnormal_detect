{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Generation Models\n",
    "\n",
    "In this part, we utilize the graph-based generation models to detect the abnormal/malicious data in the log dataset. Generation models are able to learn the underlying data distribution of the normal data. When the model is trained on the normal dataset, if a normal data sample is input and forwared through the model, the reconstruction error after the backward propagation should keeps low. However, if the input is an abnormal data sample, the reconstruction error will be relatively much higher. Therefore, through analyzing the reconstruction error, we are able to detect the abnormal data points feeded into the model. We conducted the data analysis leveraging the Denoising Diffusion Probabilistic Model (DDPM), with the Variational Autoencoder (VAE) as the comparison benchmark. Both models are integrated with the Graph Transformer model to capture the graph structure information.\n",
    "\n",
    "The training was conducted on 56,576 normal log graphs with the batch size of 32. Due to the data loeading and training process of generation models are time-consuming, we used sperate Python files to reconstruct the graph data, collate the data batches, train the models, and saved the trained model parameters. The specific code files and example tensor format are available in the GitHub repository [here](https://github.com/Klasnov/graph_abnormal_detect). In this report section, we will show the code snippets ***without*** executed outputs. The code content in this section is adapted from the tutorial code files, with modifications to our specific dataset application, like the explicit positional encoding of the graph structure based on the log sequence.\n",
    "\n",
    "\n",
    "## Training Graph Reconstruction with DGL Library\n",
    "\n",
    "We first load the networkx graph files after the previous data preprocessing. The graph data is then converted to Tensor format with DGL library, as DGL can help to easily extract and manipulate the node and edge features in the graph data.\n",
    "\n",
    "In the networkx graph, the node features we are going to use are the node type in the computational system and the node log ID. Since some ID values are very frequent appearing in the log data, for each graph with specific size of 100 nodes, we reindex the node local ID, as the node positional encoding later, by random values in the range of 0 to 99. This may avoid the model to overfit on the specific global node ID values. The edge features are the operation type between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "NUM_NODE = 100\n",
    "\n",
    "TYPES = [\"THREAD\", \"FILE\", \"REGISTRY\", \"FLOW\", \"USER_SESSION\", \"SERVICE\", \"PROCESS\", \"MODULE\", \"TASK\", \"SHELL\"]\n",
    "TYPE_MAP = {type: i for i, type in enumerate(TYPES)}\n",
    "\n",
    "ACTIONS = [\n",
    "    \"FILE_CREATE\", \"FILE_DELETE\", \"FILE_MODIFY\", \"FILE_READ\", \"FILE_RENAME\",\n",
    "    \"FILE_WRITE\", \"FLOW_MESSAGE\", \"FLOW_OPEN\", \"MODULE_LOAD\", \"PROCESS_CREATE\",\n",
    "    \"PROCESS_OPEN\", \"PROCESS_TERMINATE\", \"REGISTRY_ADD\", \"REGISTRY_EDIT\",\n",
    "    \"REGISTRY_REMOVE\", \"SERVICE_CREATE\", \"SHELL_COMMAND\", \"TASK_CREATE\",\n",
    "    \"TASK_DELETE\", \"TASK_MODIFY\", \"TASK_START\", \"THREAD_CREATE\", \"THREAD_REMOTE_CREATE\",\n",
    "    \"THREAD_TERMINATE\", \"USER_SESSION_GRANT\", \"USER_SESSION_INTERACTIVE\",\"USER_SESSION_LOGIN\",\n",
    "    \"USER_SESSION_LOGOUT\", \"USER_SESSION_REMOTE\", \"USER_SESSION_UNLOCK\"\n",
    "    ]\n",
    "ACTION_MAP = {action: i for i, action in enumerate(ACTIONS)}\n",
    "\n",
    "def nx_to_dgl(nx_graph):\n",
    "    dgl_graph = dgl.graph(([], []))\n",
    "\n",
    "    node_ids = list(nx_graph.nodes)\n",
    "    dgl_graph.add_nodes(len(node_ids))\n",
    "    nx_to_dgl_node_map = {node: i for i, node in enumerate(node_ids)}\n",
    "    if len(node_ids) != NUM_NODE:\n",
    "        raise ValueError(\"Number of nodes in graph is not 100\")\n",
    "    \n",
    "    id_set = set()\n",
    "    for node in node_ids:\n",
    "        node_data = nx_graph.nodes[node]\n",
    "        node_id = node_data.get(\"nodeID\", -1)\n",
    "        id_set.add(node_id)\n",
    "    \n",
    "    # Map nodeIDs to random integer in range of [0, 99], avoid overfitting to nodeIDs\n",
    "    id_set_len = len(id_set)\n",
    "    rand_ids = np.random.choice(100, id_set_len, replace=False)\n",
    "    rand_id_Map = {node_id: rand_id for node_id, rand_id in zip(id_set, rand_ids)}\n",
    "    \n",
    "    # Map node features\n",
    "    node_types = []\n",
    "    ids = []\n",
    "    \n",
    "    for node in node_ids:\n",
    "        node_data = nx_graph.nodes[node]\n",
    "        node_type = node_data.get(\"node_type\", \"\")\n",
    "        node_id = node_data.get(\"nodeID\", -1)\n",
    "        node_types.append(TYPE_MAP.get(node_type, -1))\n",
    "        ids.append(rand_id_Map.get(node_id, -1))\n",
    "    \n",
    "    dgl_graph.ndata[\"type\"] = torch.tensor(node_types, dtype=torch.float32)\n",
    "    dgl_graph.ndata[\"id\"] = torch.tensor(ids, dtype=torch.float32)\n",
    "    \n",
    "    # Map edge features\n",
    "    edges = list(nx_graph.edges(data=True))\n",
    "    src_nodes = []\n",
    "    dst_nodes = []\n",
    "    edge_actions = []\n",
    "    \n",
    "    for edge in edges:\n",
    "        src, dst, edge_data = edge\n",
    "        src_nodes.append(nx_to_dgl_node_map[src])\n",
    "        dst_nodes.append(nx_to_dgl_node_map[dst])\n",
    "        edge_actions.append(ACTION_MAP.get(edge_data.get(\"action\", \"\"), -1))\n",
    "    \n",
    "    dgl_graph.add_edges(src_nodes, dst_nodes)\n",
    "    dgl_graph.edata[\"action\"] = torch.tensor(edge_actions, dtype=torch.float32)\n",
    "    \n",
    "    return dgl_graph\n",
    "\n",
    "\n",
    "\n",
    "dir_path = \"data/train_graphs/\"\n",
    "if not os.path.exists(dir_path):\n",
    "    raise ValueError(\"The path does not exist\")\n",
    "\n",
    "train_graph_list = []\n",
    "for chid_dirs in os.listdir(dir_path):\n",
    "    chid_dirs_path = os.path.join(dir_path, chid_dirs)\n",
    "    if not os.path.isdir(chid_dirs_path):\n",
    "        continue\n",
    "    for file in os.listdir(chid_dirs_path):\n",
    "        if file.endswith(\".gz\"):\n",
    "            file_path = os.path.join(chid_dirs_path, file)\n",
    "            with gzip.open(file_path, \"rb\") as f:\n",
    "                nx_graph = nx.read_gml(f)\n",
    "                dgl_graph = nx_to_dgl(nx_graph)\n",
    "                train_graph_list.append(dgl_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Batching and Storage in Tensor Format\n",
    "\n",
    "To make the training process more efficient, we collate the graph data into batches with batch size of 32. The batched graph data is saved in the PyTorch tensor format, which can be directly loaded in the training process.\n",
    "\n",
    "In this process, the edge features are converted from the COO sparse matrix format into the dense weighted adjacency matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def get_weighted_adjacency_matrix(graph):\n",
    "    adj_spr = graph.adjacency_matrix(scipy_fmt=\"coo\")\n",
    "    edge_freq = graph.edata[\"action\"]\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    for i, j, freq in zip(adj_spr.row, adj_spr.col, edge_freq):\n",
    "        adj[i, j] = freq\n",
    "    adj = adj + adj.T\n",
    "    return adj\n",
    "\n",
    "\n",
    "def batch_save(graph_list, path, index, batch_size=32):\n",
    "    if len(graph_list) < batch_size:\n",
    "        batch_size = len(graph_list)\n",
    "    node_type_list = []\n",
    "    node_id_list = []\n",
    "    edge_action_list = []\n",
    "    for graph in graph_list:\n",
    "        node_type_list.append(graph.ndata[\"type\"])\n",
    "        node_id_list.append(graph.ndata[\"id\"])\n",
    "        adj = get_weighted_adjacency_matrix(graph)\n",
    "        edge_action_list.append(adj)\n",
    "    h = torch.cat(node_type_list, dim=0).view(batch_size, 100).long()\n",
    "    pe = torch.cat(node_id_list, dim=0).view(batch_size, 100).long()\n",
    "    e = torch.cat(edge_action_list, dim=0).view(batch_size, 100, 100).long()\n",
    "    torch.save(h, path + \"h_\" + str(index) + \".pt\")\n",
    "    torch.save(pe, path + \"pe_\" + str(index) + \".pt\")\n",
    "    torch.save(e, path + \"e_\" + str(index) + \".pt\")\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "def batch_graph(graph_list=None, batch_size=32, path=\"data/train/\", index=0, load=True):\n",
    "    if not load:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        num_batch = ceil(len(graph_list) / batch_size)\n",
    "        for i in range(num_batch):\n",
    "            end_batch_index = (i + 1) * batch_size\n",
    "            if end_batch_index > len(graph_list):\n",
    "                end_batch_index = len(graph_list)\n",
    "            batch_graph_list = graph_list[i * batch_size: end_batch_index]\n",
    "            save_path = path + \"batch_\" + str(i) + \"/\"\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            batch_save(batch_graph_list, save_path, i)\n",
    "            h = None; pe = None; e = None\n",
    "    else:\n",
    "        save_path = path + \"batch_\" + str(index) + \"/\"\n",
    "        if not os.path.exists(save_path):\n",
    "            raise ValueError(\"The path does not exist\")\n",
    "        h = torch.load(save_path + \"h_\" + str(index) + \".pt\", weights_only=True)\n",
    "        pe = torch.load(save_path + \"pe_\" + str(index) + \".pt\", weights_only=True)\n",
    "        e = torch.load(save_path + \"e_\" + str(index) + \".pt\", weights_only=True)\n",
    "    return h, pe, e\n",
    "\n",
    "\n",
    "_ = batch_graph(train_graph_list, batch_size=BATCH_SIZE, load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
